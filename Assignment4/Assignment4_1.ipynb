{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Assignment #4 Implementing Variational AutoEncoder - part1 MNIST data\n",
    "\n",
    "Copyright (C) Data Science Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Chaehun Shin, September\n",
    "\n",
    "In this notebook, you will learn how to implement Variational AutoEncoder(VAEs). <br>\n",
    "The goal here is to build VAEs that draw a digit(MNIST data). <br> \n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **all parts**, run the *CollectSubmission.sh* script with your **Team number** as input argument. <br>\n",
    "This will produce a zipped file called *[Your team number].zip*. Please submit this file on ETL. &nbsp;&nbsp; (Usage: ./*CollectSubmission.sh* &nbsp; Team_#)\n",
    "\n",
    "### Some helpful tutorials and references for assignment #1:\n",
    "- [1] TensorFlow official tutorials. [[link]](https://www.tensorflow.org/get_started/get_started)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\" arXiv preprint arXiv:1312.6114 (2013).\n",
    "- [4] Doersch, Carl. \"Tutorial on variational autoencoders.\" arXiv preprint arXiv:1606.05908 (2016).\n",
    "- [5] Kingma, Diederik P., and Max Welling. \"An Introduction to Variational Autoencoders.\" arXiv preprint arXiv:1906.02691 (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download and load MNIST datasets\n",
    "The MNIST dataset will be downloaded into the 'data' directory. If you want to change the directory where the data is saved, change mnist_data_dir with where you want. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import *\n",
    "import os\n",
    "from utils import load_mnist\n",
    "mnist_data_dir = './data'\n",
    "prepare_data_dir(mnist_data_dir)\n",
    "download_mnist(mnist_data_dir)\n",
    "data_array , data_y = load_mnist(os.path.join(mnist_data_dir,'mnist'))\n",
    "print(data_array.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1\"></a> 1. Build a network\n",
    "\n",
    "In this section, you will implement neural networks for (1)encoder $q_\\phi(z \\mid x)$ to encode latent variable distribution from the image of digits (2)decoder $p_\\theta(x \\mid z)$ to reconstruct the image of digits from the sample of latent variable distribution. You can use some function in *ops.py* or you can make it as you want. Just write the code in whatever way you find most clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops import conv2d\n",
    "from ops import lrelu\n",
    "from ops import de_conv\n",
    "from ops import fully_connect\n",
    "from ops import conv_cond_concat\n",
    "from ops import batch_normal\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time for an encoder. It takes img_data, img_dim(should be 28\\*28\\*1=784 here), latent_dim(dimension of the z). It should return the latent variable distribution with the dimension of latent_dim. <br>\n",
    "Because we model the latent variable distribution as multivariate Gaussian, we can make the distribution with only mean and covariance matrix. Also as we model each latent variable as independent, covariance matrix becomes a diagonal matrix and we need only (latent_dim) number elements. so we make outputs as 2 (latent_dim) dimension vectors from encoder function with neural network. I recommend to use logvar not variance itself because of scalability.\n",
    "\n",
    "<img src='./pictures/encoder.png'>\n",
    "\n",
    "Maybe you can use two neural networks for mean and logvar vectors. However it is recommended to use only one neural network with two last branches.<br> \n",
    "For example, if you use 5 layer networks, first 4 layers are shared and there are 2 5th layer each corresponding to mean and logvar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(img_data, img_dim=784, latent_dim=10, reuse=False):\n",
    "    with tf.variable_scope('enc', reuse=reuse):\n",
    "        ### ToDo ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time for a decoder model. It takes sample of the latent variable distribution(z), latent_dim(dimension of the latent variable), and img_dim(28\\*28\\*1 here). It should return the reconstruction of the original image as x_hat. <br>\n",
    "Decoder models the likelihood distributions and in here, we model each pixel as Bernoulli distribution(So we use binary cross entropy as loss function). So **you should use the sigmoid function to make the output as probability in [0, 1]**\n",
    "\n",
    "<img src='./pictures/decoder.png'>\n",
    "\n",
    "Note that you should define Tensorflow Variables within the variable scope again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(z, latent_dim=10, img_dim=784, reuse=False):\n",
    "    with tf.variable_scope('dec', reuse=reuse):\n",
    "        ### ToDo ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2\"></a> 2. Build a main part and train it\n",
    "\n",
    "In this section, you will implement the main part. You should define the loss function and reparameterization trick (TODO part). Then run the code and check the model reconstructs a digit.\n",
    "\n",
    "When you are done, run the following to check your implementations.\n",
    "\n",
    "Following code will make 'samples_for_test/vae_mnist' directory that resulting image will be saved in. You can change the directory as you want.\n",
    "\n",
    "Also, you can change all other hyperparameters such as learning rate, batch size. But be sure to define **batch size bigger than 16**.(Because, we visualize 16 images per batch in training time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_mnist\n",
    "from utils import save_images\n",
    "from utils import show_images\n",
    "from utils import vis_square\n",
    "from utils import sample_label\n",
    "from utils import getNext_batch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 \n",
    "import os\n",
    "\n",
    "learning_rate = 1e-4\n",
    "batch_size = 128\n",
    "EPOCH = 1000\n",
    "loss_step    = 500\n",
    "display_step = 2500\n",
    "latent_channel=16\n",
    "img_channel = 1\n",
    "output_size = 28\n",
    "sample_dir = 'samples_for_test/vae_mnist'\n",
    "\n",
    "if os.path.exists(sample_dir) == False:\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because sampling can't be differentiated, it needs some tricks called as reparameterization trick.<br>\n",
    "First, epsilon is sampled from unit Gaussian distribution with latent_dim. Then, scale and shift it by using mean and logvar.<br>\n",
    "Because sampling is out of graph, gradient can be flowed through all paths and encoder/decoder are trained end-to-end.\n",
    "\n",
    "<img src='./pictures/reparameterization.png'>\n",
    "Left image is original version and right image is representation by using reparameterization trick.\n",
    "\n",
    "Results are visualized in order of original image, reconstructed image, generated image from the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, output_size, output_size, img_channel])\n",
    "\n",
    "# encoding\n",
    "mean, logvar = encoder(x, img_dim=output_size*output_size*img_channel, latent_dim=latent_channel)\n",
    "\n",
    "#reparametrizing\n",
    "eps = tf.placeholder(tf.float32, [None, latent_channel])\n",
    "############## ToDo ##############\n",
    "z = \n",
    "##################################\n",
    "\n",
    "#decoding\n",
    "x_hat = decoder(z, latent_dim=latent_channel, img_dim=output_size*output_size*img_channel)\n",
    "x_hat = tf.reshape(x_hat, [batch_size, output_size, output_size, img_channel])\n",
    "\n",
    "#geneartion\n",
    "x_new = decoder(eps, latent_dim=latent_channel, img_dim=output_size*output_size*img_channel, reuse=True)\n",
    "x_new = tf.reshape(x_new, [batch_size, output_size, output_size, img_channel])\n",
    "\n",
    "############## ToDo ##############\n",
    "kl_loss = \n",
    "recon_loss = \n",
    "total_loss = (kl_loss + recon_loss)\n",
    "##################################\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    \n",
    "    for e in range(EPOCH):\n",
    "        for b in range(len(data_array)//batch_size - 1):\n",
    "            step += 1\n",
    "            \n",
    "            img, _ = getNext_batch(data_array, data_y, b, batch_size)\n",
    "            batch_eps = np.random.randn(batch_size, latent_channel)\n",
    "            \n",
    "            feed_dict = {x: img, eps: batch_eps}\n",
    "            _ = sess.run(optim, feed_dict=feed_dict)\n",
    "            \n",
    "            if step % loss_step == 0:\n",
    "                total, kl, recon = sess.run([total_loss, kl_loss, recon_loss], feed_dict=feed_dict)\n",
    "                print('<Epoch:%d/%d, Step:%03d/%d>total_loss: %.4f, kl_loss: %.4f, recon_loss: %.4f'\n",
    "                      %(e+1, EPOCH, b+1, len(data_array)//batch_size-1, total, kl, recon))\n",
    "                \n",
    "            if np.mod(step, display_step) == 1:\n",
    "                recon_imgs, gen_imgs = sess.run([x_hat, x_new], feed_dict=feed_dict)\n",
    "                recon_imgs = recon_imgs[:16, :, :, :]\n",
    "                gen_imgs = gen_imgs[:16, :, :, :]\n",
    "                plt.subplot(1, 3, 1)\n",
    "                imgplot1 = show_images(img[:16, :, :, :], [4, 4])\n",
    "                plt.subplot(1, 3, 2)\n",
    "                imgplot2= show_images(recon_imgs, [4, 4])\n",
    "                plt.subplot(1, 3, 3)\n",
    "                imgplot3 = show_images(gen_imgs, [4, 4])\n",
    "                plt.show()\n",
    "        \n",
    "        idx_list = np.arange(len(data_array))\n",
    "        np.random.shuffle(idx_list)\n",
    "        data_array = data_array[idx_list]\n",
    "        data_y = data_y[idx_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
