{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Assignment #4 Implementing Conditional Generative Adversarial Nets - part2 MNIST data\n",
    "\n",
    "Copyright (C) Data Science Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Jaeyoon Yoo, November 2017\n",
    "\n",
    "In this notebook, you will learn how to implement conditional Genverative Adversarial Nets (cGANs) <br>\n",
    "The goal here is to build GANs that draw a digit(MNIST data) given its label. <br> \n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **all parts**, run the *CollectSubmission.sh* script with your **Team number** as input argument. <br>\n",
    "This will produce a zipped file called *[Your team number].zip*. Please submit this file on ETL. &nbsp;&nbsp; (Usage: ./*CollectSubmission.sh* &nbsp; Team_#)\n",
    "\n",
    "### Some helpful tutorials and references for assignment #2:\n",
    "- [1] TensorFlow official tutorials. [[link]](https://www.tensorflow.org/get_started/get_started)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] Goodfellow, Ian, et al. \"Generative adversarial nets.\" Advances in neural information processing systems. 2014.\n",
    "- [4] Mirza, Mehdi, and Simon Osindero. \"Conditional generative adversarial nets.\" arXiv preprint arXiv:1411.1784 (2014).\n",
    "- [5] Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download and load MNIST datasets\n",
    "The MNIST datasets will be downloaded into the 'data' directory. If you want to change the directory the data is saved in, change mnist_data_dir with where you want. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import *\n",
    "import os\n",
    "from utils import load_mnist\n",
    "mnist_data_dir = './data'\n",
    "prepare_data_dir(mnist_data_dir)\n",
    "download_mnist(mnist_data_dir)\n",
    "data_array , data_y = load_mnist(os.path.join(mnist_data_dir,'mnist'))\n",
    "print(data_array.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1\"></a> 1. Build a network\n",
    "\n",
    "In this section, you will implement neural networks for (1) generative model to draw a digit (2) discriminative model to distinguish real image from generated image. You can use some function in *ops.py* or you can make it as you want. Just write the code in whatever way you find most clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops import conv2d\n",
    "from ops import lrelu\n",
    "from ops import de_conv\n",
    "from ops import fully_connect\n",
    "from ops import conv_cond_concat\n",
    "from ops import batch_normal\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time for a generative model. It takes batch size, sample size(the dimension of latent variable or so called *noise*), y_dim(the dimension of label), the output size(should be 28 here) and z,y (Tensorflow Variables for latent variable and label respectively). It should return the image 28x28 output of which each element is in [0,1]. Note that you should define Tensorflow Variables within the variable scope.\n",
    "\n",
    "You should utilize the label variable y in your model. The simplest way is concatenate the label variable and features or raw image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gern_net(batch_size, z , y , sample_size, y_dim, output_size):\n",
    "    with tf.variable_scope('gen'):\n",
    "        #### TODO ####\n",
    "    ####TODO ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time for a discriminative model. It takes image data and label variable y. It should return the value for which the model is certain that the image is real and its logit. (i.e return the value in [0,1] and its logit). Note that you should define Tensorflow Variables within the variable scope again.\n",
    "\n",
    "You may use the label variable or not. Here, again concatenating is the simplest way to utilize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_net(image_data , y, reuse=False):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        #### TODO ####\n",
    "    #### TODO ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2\"></a> 2. Build a main part and train it\n",
    "\n",
    "In this section, you will implement the main part. You should define the loss function for each model(TODO part). Then run the code and check the model draws a digit for given label.\n",
    "\n",
    "When you are done, run the following to check your implementations.\n",
    "\n",
    "Following code will make 'samples_for_test' directory that resulting image will be saved in. You can change the directory as you want.\n",
    "\n",
    "Also, you can change all other hyperparameters such as learning rate, batch size. But be sure to define **batch size bigger than 100**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_mnist\n",
    "from utils import save_images\n",
    "from utils import vis_square\n",
    "from utils import sample_label\n",
    "from utils import getNext_batch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "learning_rate = 0.0002\n",
    "batch_size = 128\n",
    "EPOCH = 2\n",
    "loss_step    = 50\n",
    "display_step = 50\n",
    "sample_size = 100\n",
    "y_dim = 10\n",
    "channel = 1\n",
    "output_size = 28\n",
    "sample_dir = 'samples_for_test'\n",
    "\n",
    "if os.path.exists(sample_dir) == False:\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function in the TODO part. Modify only loss part.\n",
    "\n",
    "Discriminator loss : log[D(x)] + log[1-D(G(z))]\n",
    "Generator loss     : log[D(G(z)]\n",
    "\n",
    "If you write the code correctly and run the code, it will display 10x10 images(each row shows one of the number). \n",
    "\n",
    "Also, it will save the generated images in the 'sample_dir' directory. So if you want to see it, check that directory.\n",
    "\n",
    "**Please be sure that you ran the above codes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_z = np.random.uniform(-1 , 1 , size = [batch_size , sample_size])\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None , y_dim])\n",
    "\n",
    "images = tf.placeholder(tf.float32, [batch_size, output_size, output_size, channel])\n",
    "\n",
    "z = tf.placeholder(tf.float32, [None , sample_size])\n",
    "\n",
    "fake_images = gern_net(batch_size, z , y ,sample_size, y_dim,output_size)\n",
    "\n",
    "##the loss of gerenate network\n",
    "D_pro , D_logits = dis_net(images, y ,  False)\n",
    "\n",
    "G_pro, G_logits = dis_net(fake_images , y , True)\n",
    "\n",
    "#### TODO ####\n",
    "# DEFINE LOSS FUNCTION #\n",
    "\n",
    "D_loss = \n",
    "G_loss = \n",
    "\n",
    "#############\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "\n",
    "d_var = [var for var in t_vars if 'dis' in var.name]\n",
    "g_var = [var for var in t_vars if 'gen' in var.name]\n",
    "\n",
    "opti_D = tf.train.AdamOptimizer(learning_rate=learning_rate , beta1=0.5).minimize(D_loss , var_list=d_var)\n",
    "opti_G = tf.train.AdamOptimizer(learning_rate=learning_rate , beta1=0.5).minimize(G_loss , var_list=g_var)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "    e = 0\n",
    "    step = 0\n",
    "\n",
    "    while e <= EPOCH:\n",
    "        batch_num = 0\n",
    "        while batch_num < len(data_array) / batch_size - 1:\n",
    "\n",
    "            step = step + 1\n",
    "\n",
    "            realbatch_array , real_labels = getNext_batch(data_array , data_y , batch_num, batch_size)\n",
    "            \n",
    "            #Get the z\n",
    "            batch_z = np.random.uniform(-1 , 1 , size=[batch_size , sample_size])\n",
    "\n",
    "            _ = sess.run(opti_D, feed_dict={images:realbatch_array, z:batch_z , y:real_labels})\n",
    "            _ = sess.run(opti_G, feed_dict={z: batch_z , y:real_labels})\n",
    "\n",
    "            batch_num += 1\n",
    "\n",
    "            if step % loss_step == 0:\n",
    "\n",
    "                d_get_loss = sess.run(D_loss , feed_dict = {images:realbatch_array , z:batch_z , y:real_labels})\n",
    "                g_get_loss = sess.run(G_loss , feed_dict = {z: batch_z , y:real_labels})\n",
    "                print(\"EPOCH %d step %d: D: loss = %.7f G: loss=%.7f \" % (e , step , d_get_loss , g_get_loss))\n",
    "\n",
    "            if np.mod(step , display_step) == 1:\n",
    "\n",
    "                sample_images = sess.run(fake_images , feed_dict={z:sample_z , y:sample_label(batch_size)})\n",
    "                sample_images = sample_images[:100,:,:,:]\n",
    "                image_name = './{}/train_{:02d}_{:04d}.png'.format(sample_dir , e , step)\n",
    "                save_images(sample_images , [10,10] , image_name)\n",
    "\n",
    "        img = mpimg.imread(image_name)\n",
    "        imgplot = plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        e = e + 1\n",
    "        batch_num = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
