{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Assignment #2 Part 1: Implementing Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn how to implement convolutional neural networks (CNNs) <font color=red>**without using deep learning frameworks**</font>. <br>\n",
    "The goal here is to get better understanding of CNNs before using the **TensorFlow** deep learning framework in part 2&3. <br> \n",
    "There are **2 sections**, and in each section, you need to follow the instructions to complete the skeleton codes and explain them.\n",
    "\n",
    "1. [Forward pass](#1) ( 15 points )\n",
    "2. [Backward pass](#2) ( 15 points )\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **all three parts**, run the *CollectSubmission.sh* script with your **Team number** as input argument. <br>\n",
    "This will produce a compressed file called *team_#.tar.gz*. Please submit this file on ETL. &nbsp;&nbsp; (Usage example: ./*CollectSubmission.sh* &nbsp; team_77)\n",
    "\n",
    "### Some helpful tutorials and references for assignment #2:\n",
    "- [1] TensorFlow official tutorials. [[link]](https://www.tensorflow.org/get_started/get_started)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] Iandola et al, \"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and < 0.5MB model size\", arXiv 2016. [[pdf]](https://arxiv.org/pdf/1602.07360.pdf)\n",
    "- [4] Simonyan et al., \"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\", ICLR Workshop 2014. [[pdf]](https://arxiv.org/pdf/1312.6034.pdf)\n",
    "- [5] Szegedy et al., \"Intriguing properties of neural networks\", ICLR 2014. [[pdf]](https://arxiv.org/pdf/1312.6199.pdf)\n",
    "- [6] Szegedy et al., \"Going deeper with convolutions\", CVPR 2015. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)\n",
    "- [7] Yosinski et al., \"Understanding Neural Networks Through Deep Visualization\", ICML Workshop 2015. [[pdf]](http://yosinski.com/media/papers/Yosinski__2015__ICML_DL__Understanding_Neural_Networks_Through_Deep_Visualization__.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "The datasets in the *Utils* directory will be loaded automatically. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Utils.data_utils import load_images\n",
    "from Utils.layer_utils import Test_conv_forward, Test_conv_forward_IP, Test_conv_backward\n",
    "from Utils.layer_utils import Test_max_pool_forward, Test_max_pool_backward\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load sample images\n",
    "Sample_images = load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1\"></a> 1. Forward pass ( 15 points )\n",
    "\n",
    "In this section, you will implement forward passes for **(1) convolution with padding=valid** (w/ linear activation), **(2) convolution with padding=same** and **(3) max pooling** layers. 5 points will be allocated for each. Using the code provided as guidance, complete the functions `conv_forward` and `max_pool_forward` in *Utils/layer_utils.py* file. You don't have to worry too much about computational efficiency; just write the code in whatever way you find most clear. \n",
    "\n",
    "When you are done, run the following to check your implementations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_forward for padding=valid\n",
      "8 2 valid [1 2 3 1]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-75b63958491c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compare your convolution forward outputs to ours; difference should be around 4e-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing conv_forward for padding=valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'difference: %e\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mTest_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing conv_forward for padding=same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SNUClass/3rdSemester/DeepLearning/deep-learning-snu/Assignment2/Utils/layer_utils.py\u001b[0m in \u001b[0;36mTest_conv_forward\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mconv_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'stride'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'padding'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         correct_out = np.array([[[[  5.12264676e-02,  -7.46786231e-02],\n\u001b[1;32m    139\u001b[0m                                   [ -1.46819650e-03,   4.58694441e-02]],\n",
      "\u001b[0;32m~/SNUClass/3rdSemester/DeepLearning/deep-learning-snu/Assignment2/Utils/layer_utils.py\u001b[0m in \u001b[0;36mconv_forward\u001b[0;34m(x, w, b, conv_param)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#a output data has size H_out, W_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mH_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mWH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mW_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mWW\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# Compare your convolution forward outputs to ours; difference should be around 4e-8\n",
    "print('Testing conv_forward for padding=valid')\n",
    "print('difference: %e\\n' % Test_conv_forward(1))\n",
    "\n",
    "print('Testing conv_forward for padding=same')\n",
    "print('difference: %e\\n' % Test_conv_forward(2))\n",
    "\n",
    "# Compare your max pooling forward outputs to ours; difference should be around 6e-8\n",
    "print('Testing max_pool_forward')\n",
    "print('difference: %e' % Test_max_pool_forward())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Image processing via convolutions\n",
    "\n",
    "As fun way to both check your implementation and gain a better understanding of the type of operation that convolutional layers can perform, we have manually set up filters that perform common image processing operations (grayscale conversion and edge detection). The convolution forward pass will apply these operations to each of the input images. We can then visualize the results as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_conv_forward_IP(Sample_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2\"></a> 2. Backward pass ( 15 points )\n",
    "\n",
    "In this section, you will implement backward passes for **(1) convolution with padding=valid** (w/ linear activation), **(2) convolution with padding=same** and **(3) max pooling** layers. 5 points will be allocated for each. Using the code provided as guidance, complete the functions `conv_backward` and `max_pool_backward` in *Utils/layer_utils.py* file. You don't have to worry too much about computational efficiency; just write the code in whatever way you find most clear.\n",
    "\n",
    "When you are done, run the following to check your implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare your convolution backward outputs to ours; difference should be around 1e-9\n",
    "print('Testing conv_backward for padding=valid')\n",
    "Diff1 = Test_conv_backward(1)\n",
    "print('difference dx: %e' % Diff1[0])\n",
    "print('difference dw: %e' % Diff1[1])\n",
    "print('difference db: %e\\n' % Diff1[2])\n",
    "\n",
    "print('Testing conv_backward for padding=same')\n",
    "Diff2 = Test_conv_backward(2)\n",
    "print('difference dx: %e' % Diff2[0])\n",
    "print('difference dw: %e' % Diff2[1])\n",
    "print('difference db: %e\\n' % Diff2[2])\n",
    "\n",
    "# Compare your max pooling backward outputs to ours; difference should be around 1e-12\n",
    "print('Testing max_pool_backward')\n",
    "print('difference dx: %e' % Test_max_pool_backward())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
